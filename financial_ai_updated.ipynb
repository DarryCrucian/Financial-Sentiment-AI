{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487aff9f",
   "metadata": {},
   "source": [
    "# Financial AI - Refactored Notebook\n",
    "This notebook contains the refactored code for the Financial AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f15b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x222f492bf50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import gradio as gr\n",
    "\n",
    "# Initialize spaCy once and load the model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('sentencizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c5ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to initialize all models at once\n",
    "def initialize_models():\n",
    "    try:\n",
    "        asr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\n",
    "        summarizer = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\n",
    "        fin_model = pipeline(\"sentiment-analysis\", model='yiyanghkust/finbert-tone', tokenizer='yiyanghkust/finbert-tone')\n",
    "        return asr, summarizer, fin_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing models: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e4ea207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for splitting text into sentences\n",
    "def split_in_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits the input text into sentences using spaCy.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be split.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sentences.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [str(sent).strip() for sent in doc.sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef5974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to transcribe audio using ASR\n",
    "def transcribe_audio(audio, pipelines):\n",
    "    \"\"\"\n",
    "    Transcribes audio to text using the ASR pipeline.\n",
    "\n",
    "    Args:\n",
    "        audio: Audio input to be transcribed.\n",
    "        pipelines (dict): Dictionary containing the initialized models.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pipelines['asr'](audio)[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9ddd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for summarizing text\n",
    "def summarize_text(text, pipelines):\n",
    "    \"\"\"\n",
    "    Summarizes the input text using the summarizer pipeline.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be summarized.\n",
    "        pipelines (dict): Dictionary containing the initialized models.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = pipelines['summarizer'](text)\n",
    "        return resp[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c777c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for sentiment analysis using FinBERT\n",
    "def text_to_sentiment(text, pipelines):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of the input text using the FinBERT model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text for sentiment analysis.\n",
    "        pipelines (dict): Dictionary containing the initialized models.\n",
    "\n",
    "    Returns:\n",
    "        str: The sentiment label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pipelines['sentiment'](text)[0][\"label\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentiment analysis: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528064cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize pipelines\n",
    "pipelines = {\n",
    "    'asr': None,\n",
    "    'summarizer': None,\n",
    "    'sentiment': None\n",
    "}\n",
    "\n",
    "# Load the models into the pipeline dictionary\n",
    "pipelines['asr'], pipelines['summarizer'], pipelines['sentiment'] = initialize_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec27b456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "IMPORTANT: You are using gradio version 3.41.0, however version 5.0.1 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 62, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\435894753.py\", line 17, in analyze_sentiment_trend_with_pipeline\n",
      "    plot_sentiment_trend(df)\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\131228912.py\", line 32, in plot_sentiment_trend\n",
      "    df['date'] = pd.to_datetime(df['date'])\n",
      "                                ~~^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 3761, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\range.py\", line 349, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'date'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\435894753.py\", line 16, in analyze_sentiment_trend_with_pipeline\n",
      "    df = analyze_sentiment_over_time(reports, pipelines)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\131228912.py\", line 17, in analyze_sentiment_over_time\n",
      "    date = report['date']\n",
      "           ~~~~~~^^^^^^^^\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\435894753.py\", line 16, in analyze_sentiment_trend_with_pipeline\n",
      "    df = analyze_sentiment_over_time(reports, pipelines)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\131228912.py\", line 17, in analyze_sentiment_over_time\n",
      "    date = report['date']\n",
      "           ~~~~~~^^^^^^^^\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\435894753.py\", line 16, in analyze_sentiment_trend_with_pipeline\n",
      "    df = analyze_sentiment_over_time(reports, pipelines)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\131228912.py\", line 17, in analyze_sentiment_over_time\n",
      "    date = report['date']\n",
      "           ~~~~~~^^^^^^^^\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\435894753.py\", line 16, in analyze_sentiment_trend_with_pipeline\n",
      "    df = analyze_sentiment_over_time(reports, pipelines)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\131228912.py\", line 17, in analyze_sentiment_over_time\n",
      "    date = report['date']\n",
      "           ~~~~~~^^^^^^^^\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vaishnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\435894753.py\", line 16, in analyze_sentiment_trend_with_pipeline\n",
      "    df = analyze_sentiment_over_time(reports, pipelines)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnav\\AppData\\Local\\Temp\\ipykernel_11848\\131228912.py\", line 17, in analyze_sentiment_over_time\n",
      "    date = report['date']\n",
      "           ~~~~~~^^^^^^^^\n",
      "TypeError: string indices must be integers, not 'str'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def transcribe_audio_with_pipeline(audio):\n",
    "    return transcribe_audio(audio, pipelines)\n",
    "\n",
    "def summarize_text_with_pipeline(text):\n",
    "    return summarize_text(text, pipelines)\n",
    "\n",
    "def text_to_sentiment_with_pipeline(text):\n",
    "    return text_to_sentiment(text, pipelines)\n",
    "\n",
    "def create_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Financial Analyst AI\")\n",
    "        gr.Markdown(\"This project applies AI trained to analyze earning calls and other financial documents.\")\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                audio_file = gr.Audio(source=\"microphone\", type=\"filepath\")\n",
    "                text_box = gr.Textbox(label=\"Transcribed Text\")\n",
    "                b1 = gr.Button(\"Recognize Speech\")\n",
    "                b1.click(fn=transcribe_audio_with_pipeline, inputs=audio_file, outputs=text_box)\n",
    "                \n",
    "                summary_box = gr.Textbox(label=\"Summary\")\n",
    "                b2 = gr.Button(\"Summarize Text\")\n",
    "                b2.click(fn=summarize_text_with_pipeline, inputs=text_box, outputs=summary_box)\n",
    "                \n",
    "                sentiment_label = gr.Label(label=\"Financial Tone\")\n",
    "                b3 = gr.Button(\"Classify Financial Tone\")\n",
    "                b3.click(fn=text_to_sentiment_with_pipeline, inputs=summary_box, outputs=sentiment_label)\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "# Launch the interface\n",
    "create_interface()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
