{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTImz6SNFrzj",
        "outputId": "1c12cfe2-f082-4d0b-b45f-b1079b3d45aa"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install gradio\n",
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_-iGzJ7_4Vw",
        "outputId": "9020c2a2-9ef0-4e39-f6a2-eb8dc729a7fa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.system(\"pip install gradio==3.0.18\")\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
        "import gradio as gr\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe('sentencizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HrJiEcVU_KEL",
        "outputId": "405ad98a-6fb5-442d-8e73-13695e5463d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_in_sentences(text):\n",
        "    doc = nlp(text)\n",
        "    return [str(sent).strip() for sent in doc.sents]\n",
        "\n",
        "def make_spans(text,results):\n",
        "    results_list = []\n",
        "    for i in range(len(results)):\n",
        "        results_list.append(results[i]['label'])\n",
        "    facts_spans = []\n",
        "    facts_spans = list(zip(split_in_sentences(text),results_list))\n",
        "    return facts_spans\n",
        "    \n",
        "auth_token = os.environ.get(\"HF_Token\")\n",
        "\n",
        "##Speech Recognition\n",
        "asr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\n",
        "def transcribe(audio):\n",
        "    text = asr(audio)[\"text\"]\n",
        "    return text\n",
        "def speech_to_text(speech):\n",
        "    text = asr(speech)[\"text\"]\n",
        "    return text\n",
        "\n",
        "##Summarization \n",
        "summarizer = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\n",
        "def summarize_text(text):\n",
        "    resp = summarizer(text)\n",
        "    stext = resp[0]['summary_text']\n",
        "    return stext\n",
        "\n",
        "##Fiscal Tone Analysis\n",
        "fin_model= pipeline(\"sentiment-analysis\", model='yiyanghkust/finbert-tone', tokenizer='yiyanghkust/finbert-tone')\n",
        "def text_to_sentiment(text):\n",
        "    sentiment = fin_model(text)[0][\"label\"]\n",
        "    return sentiment \n",
        "\n",
        "##Company Extraction    \n",
        "def fin_ner(text):\n",
        "    api = gr.Interface.load(\"dslim/bert-base-NER\", src='models', use_auth_token=auth_token)\n",
        "    replaced_spans = api(text)\n",
        "    return replaced_spans    \n",
        "\n",
        "##Fiscal Sentiment by Sentence\n",
        "def fin_ext(text):\n",
        "    results = fin_model(split_in_sentences(text))\n",
        "    return make_spans(text,results)\n",
        "    \n",
        "##Forward Looking Statement\n",
        "def fls(text):\n",
        "#    fls_model = pipeline(\"text-classification\", model=\"yiyanghkust/finbert-fls\", tokenizer=\"yiyanghkust/finbert-fls\")\n",
        "    fls_model = pipeline(\"text-classification\", model=\"demo-org/finbert_fls\", tokenizer=\"demo-org/finbert_fls\", use_auth_token=auth_token)\n",
        "    results = fls_model(split_in_sentences(text))\n",
        "    return make_spans(text,results) \n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"## Financial Analyst AI\")\n",
        "    gr.Markdown(\"This project applies AI trained to analyze earning calls and other financial documents.\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            audio_file = gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "            with gr.Row():\n",
        "                b1 = gr.Button(\"Recognize Speech\") \n",
        "            with gr.Row():\n",
        "                text = gr.Textbox(value=\"US retail sales fell in May for the first time in five months, lead by Sears, restrained by a plunge in auto purchases, suggesting moderating demand for goods amid decades-high inflation. The value of overall retail purchases decreased 0.3%, after a downwardly revised 0.7% gain in April, Commerce Department figures showed Wednesday. Excluding Tesla vehicles, sales rose 0.5% last month. The department expects inflation to continue to rise.\")\n",
        "                b1.click(speech_to_text, inputs=audio_file, outputs=text)\n",
        "            with gr.Row():\n",
        "                b2 = gr.Button(\"Summarize Text\")\n",
        "                stext = gr.Textbox()\n",
        "                b2.click(summarize_text, inputs=text, outputs=stext)     \n",
        "            with gr.Row():\n",
        "                b3 = gr.Button(\"Classify Financial Tone\")\n",
        "                label = gr.Label()\n",
        "                b3.click(text_to_sentiment, inputs=stext, outputs=label)  \n",
        "        with gr.Column():\n",
        "            b5 = gr.Button(\"Financial Tone and Forward Looking Statement Analysis\")\n",
        "            with gr.Row():\n",
        "                fin_spans = gr.HighlightedText()\n",
        "                b5.click(fin_ext, inputs=text, outputs=fin_spans)\n",
        "            with gr.Row():\n",
        "                fls_spans = gr.HighlightedText()\n",
        "                b5.click(fls, inputs=text, outputs=fls_spans)\n",
        "            with gr.Row():\n",
        "                b4 = gr.Button(\"Identify Companies & Locations\")\n",
        "                replaced_spans = gr.HighlightedText()\n",
        "                b4.click(fin_ner, inputs=text, outputs=replaced_spans)\n",
        "    \n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V6pj2fGIdqZ"
      },
      "outputs": [],
      "source": [
        "# @authors- Aryaman Pattnayak and PN Tejeshwar Sarma"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
